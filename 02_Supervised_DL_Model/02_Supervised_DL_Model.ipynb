{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMDMYBkZrNrFegMbM+X0L2G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g2T7VDlCItVh","executionInfo":{"status":"ok","timestamp":1765535903363,"user_tz":-330,"elapsed":44140,"user":{"displayName":"Dev Kalra","userId":"06956701992542561494"}},"outputId":"bf26ba54-2eba-4b45-e961-e11b9112c723"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Device: cpu\n"]}],"source":["!pip install -q torch torchvision scikit-learn pandas pyarrow tqdm\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os, random, math, time\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score, f1_score, precision_recall_fscore_support\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","from tqdm import tqdm\n","\n","# reproducibility\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device:\", DEVICE)\n"]},{"cell_type":"code","source":["# Edit DATA_PATH if you already have processed file\n","# Accepts parquet or csv. If your processed file exists, set it.\n","DATA_PATH = '/content/drive/MyDrive/loan-data/processed_sample.parquet'  # change if needed\n","FALLBACK_RAW = '/content/drive/MyDrive/loan-data/accepted_sample.csv'     # raw sample if processed not present\n","\n","def load_data(path):\n","    if path.endswith('.parquet'):\n","        return pd.read_parquet(path)\n","    else:\n","        return pd.read_csv(path, low_memory=False)\n","\n","if os.path.exists(DATA_PATH):\n","    df = load_data(DATA_PATH)\n","    print(\"Loaded processed file:\", DATA_PATH)\n","elif os.path.exists(FALLBACK_RAW):\n","    print(\"Processed not found. Will do quick fallback preprocessing from raw sample.\")\n","    raw = pd.read_csv(FALLBACK_RAW, low_memory=False)\n","    # Quick fallback preprocess: keep small set of numeric features + target\n","    # This is minimal; replace with your real preprocessing if you have it.\n","    # Create binary target\n","    def map_target(x):\n","        x = str(x).lower()\n","        if 'fully paid' in x: return 0\n","        if 'charged off' in x or 'default' in x: return 1\n","        return np.nan\n","    raw['target'] = raw['loan_status'].apply(map_target)\n","    keep = ['loan_amnt','int_rate','annual_inc','dti','fico_range_low','fico_range_high','term','emp_length','purpose','home_ownership','target']\n","    keep = [c for c in keep if c in raw.columns]\n","    df = raw[keep].copy()\n","    # basic cleaning\n","    if 'int_rate' in df.columns:\n","        df['int_rate'] = df['int_rate'].astype(str).str.replace('%','').astype(float)\n","    # simplify term like \"36 months\" -> 36\n","    if 'term' in df.columns:\n","        df['term'] = df['term'].astype(str).str.extract(r'(\\d+)').astype(float)\n","    # fill numeric na with median, categorical with mode\n","    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n","    cat_cols = [c for c in df.columns if c not in num_cols and c!='target']\n","    for c in num_cols:\n","        df[c] = df[c].fillna(df[c].median())\n","    for c in cat_cols:\n","        df[c] = df[c].fillna('MISSING').astype(str)\n","    # one-hot a few low-cardinal cats\n","    from sklearn.preprocessing import OneHotEncoder\n","    low_cat = [c for c in ['emp_length','purpose','home_ownership'] if c in df.columns]\n","    if low_cat:\n","        ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n","        ohe_mat = ohe.fit_transform(df[low_cat])\n","        ohe_cols = list(ohe.get_feature_names_out(low_cat))\n","        ohe_df = pd.DataFrame(ohe_mat, columns=ohe_cols, index=df.index)\n","        df = pd.concat([df.drop(columns=low_cat), ohe_df], axis=1)\n","    # drop rows with no target\n","    df = df[df['target'].notna()].reset_index(drop=True)\n","    print(\"Fallback processed rows:\", df.shape)\n","else:\n","    raise FileNotFoundError(\"No processed file found and no raw sample found. Upload one to Drive and set DATA_PATH.\")\n","\n","# Final check\n","print(\"Data shape:\", df.shape)\n","print(\"Columns sample:\", df.columns.tolist()[:30])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nRpBRSdxI1ti","executionInfo":{"status":"ok","timestamp":1765535909645,"user_tz":-330,"elapsed":2869,"user":{"displayName":"Dev Kalra","userId":"06956701992542561494"}},"outputId":"1c9d1f34-1975-4827-e78b-7516cff0fd1b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded processed file: /content/drive/MyDrive/loan-data/processed_sample.parquet\n","Data shape: (113034, 15)\n","Columns sample: ['loan_amnt', 'int_rate', 'annual_inc', 'dti', 'fico_range_low', 'fico_range_high', 'term_ 36 months', 'term_ 60 months', 'home_ownership_ANY', 'home_ownership_MORTGAGE', 'home_ownership_NONE', 'home_ownership_OTHER', 'home_ownership_OWN', 'home_ownership_RENT', 'target']\n"]}]},{"cell_type":"code","source":["# Ensure target is int\n","df['target'] = df['target'].astype(int)\n","\n","# Define feature columns (all except 'target')\n","FEATURES = [c for c in df.columns if c != 'target']\n","print(\"Num features:\", len(FEATURES))\n","\n","# Optional: drop any remaining non-numeric columns\n","non_numeric = [c for c in FEATURES if not np.issubdtype(df[c].dtype, np.number)]\n","if non_numeric:\n","    print(\"Dropping non-numeric features (very small projects should encode instead):\", non_numeric)\n","    FEATURES = [c for c in FEATURES if c not in non_numeric]\n","    df = df[FEATURES + ['target']]\n","\n","X = df[FEATURES].values.astype(np.float32)\n","y = df['target'].values.astype(np.int64)\n","\n","# train/val/test split (stratify)\n","X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.20, random_state=SEED, stratify=y)\n","X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.20, random_state=SEED, stratify=y_temp)\n","\n","print(\"train/val/test sizes:\", X_train.shape[0], X_val.shape[0], X_test.shape[0])\n","\n","# Create PyTorch datasets/dataloaders\n","BATCH = 256\n","train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n","val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n","test_ds  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n","\n","train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, drop_last=False)\n","val_loader   = DataLoader(val_ds, batch_size=BATCH, shuffle=False)\n","test_loader  = DataLoader(test_ds, batch_size=BATCH, shuffle=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"86EFecA6JCJc","executionInfo":{"status":"ok","timestamp":1765535920015,"user_tz":-330,"elapsed":412,"user":{"displayName":"Dev Kalra","userId":"06956701992542561494"}},"outputId":"36e936fa-9f88-475c-c36d-93f1c6c629c7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Num features: 14\n","train/val/test sizes: 72341 18086 22607\n"]}]},{"cell_type":"code","source":["INPUT_DIM = X_train.shape[1]\n","HIDDEN = [256, 128]   # change if desired\n","DROPOUT = 0.2\n","\n","class MLP(nn.Module):\n","    def __init__(self, in_dim, hidden_dims, dropout=0.2):\n","        super().__init__()\n","        layers = []\n","        prev = in_dim\n","        for h in hidden_dims:\n","            layers.append(nn.Linear(prev, h))\n","            layers.append(nn.BatchNorm1d(h))\n","            layers.append(nn.ReLU(inplace=True))\n","            layers.append(nn.Dropout(dropout))\n","            prev = h\n","        layers.append(nn.Linear(prev,1))  # single logit\n","        self.net = nn.Sequential(*layers)\n","    def forward(self, x):\n","        return self.net(x).squeeze(-1)  # returns (batch,)\n","\n","model = MLP(INPUT_DIM, HIDDEN, dropout=DROPOUT).to(DEVICE)\n","print(model)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L0YM1Oz1JDz2","executionInfo":{"status":"ok","timestamp":1765535934505,"user_tz":-330,"elapsed":82,"user":{"displayName":"Dev Kalra","userId":"06956701992542561494"}},"outputId":"d6a557c2-ce93-4de7-fd43-664f95fe19ed"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["MLP(\n","  (net): Sequential(\n","    (0): Linear(in_features=14, out_features=256, bias=True)\n","    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.2, inplace=False)\n","    (4): Linear(in_features=256, out_features=128, bias=True)\n","    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): ReLU(inplace=True)\n","    (7): Dropout(p=0.2, inplace=False)\n","    (8): Linear(in_features=128, out_features=1, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["# -------------------------\n","# 4) Loss, optimizer, scheduler, utils  (FIXED)\n","# -------------------------\n","\n","# compute pos_weight from training labels\n","pos = int(y_train.sum())\n","neg = int(len(y_train) - pos)\n","pos_weight = torch.tensor([neg / (pos + 1e-9)], dtype=torch.float32).to(DEVICE)\n","print(\"pos,neg,pos_weight:\", pos, neg, float(pos_weight.item()))\n","\n","criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n","\n","# FIXED: remove verbose=True because your PyTorch version doesn't support it\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer,\n","    mode='max',\n","    factor=0.5,\n","    patience=3\n",")\n","\n","def get_preds_labels(loader):\n","    model.eval()\n","    all_probs = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for xb, yb in loader:\n","            xb = xb.to(DEVICE).float()\n","            logits = model(xb)                 # (batch,1)\n","            probs  = torch.sigmoid(logits)     # (batch,1)\n","            all_probs.append(probs.cpu().numpy())\n","            all_labels.append(yb.cpu().numpy())\n","    probs = np.vstack(all_probs).reshape(-1)\n","    labels = np.vstack(all_labels).reshape(-1)\n","    return probs, labels\n","\n","def eval_on(loader):\n","    probs, labels = get_preds_labels(loader)\n","    auc = roc_auc_score(labels, probs) if len(np.unique(labels))>1 else float('nan')\n","    preds = (probs >= 0.5).astype(int)\n","    f1 = f1_score(labels, preds, zero_division=0)\n","    precision, recall, _, _ = precision_recall_fscore_support(labels, preds, average='binary', zero_division=0)\n","    return {\n","        'auc': float(auc),\n","        'f1': float(f1),\n","        'precision': float(precision),\n","        'recall': float(recall)\n","    }\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7eIReVrWJHff","executionInfo":{"status":"ok","timestamp":1765536566019,"user_tz":-330,"elapsed":24,"user":{"displayName":"Dev Kalra","userId":"06956701992542561494"}},"outputId":"db2e99a6-15b7-4308-c3f0-5c0fb251c47a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["pos,neg,pos_weight: 8642 63699 7.370863437652588\n"]}]},{"cell_type":"code","source":["# -------------------------\n","# 5) Training loop\n","# -------------------------\n","\n","EPOCHS = 30\n","best_val = -1.0\n","best_state = None\n","CKPT_PATH = os.path.join(PROJ_DRIVE, \"best_mlp_checkpoint.pt\")\n","\n","for epoch in range(1, EPOCHS+1):\n","    model.train()\n","    epoch_loss = 0.0\n","\n","    for xb, yb in train_loader:\n","        xb = xb.to(DEVICE).float()\n","        yb = yb.to(DEVICE).float()   # shape (batch,1)\n","\n","        optimizer.zero_grad()\n","        logits = model(xb)           # shape (batch,1)\n","        loss = criterion(logits, yb)\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item() * xb.size(0)\n","\n","    epoch_loss = epoch_loss / len(train_loader.dataset)\n","\n","    # eval\n","    val_metrics = eval_on(val_loader)\n","    print(f\"Epoch {epoch:02d} loss {epoch_loss:.6f}  val_auc {val_metrics['auc']:.4f}  val_f1 {val_metrics['f1']:.4f}\")\n","\n","    # scheduler (NO verbose arg)\n","    scheduler.step(val_metrics['auc'] if not math.isnan(val_metrics['auc']) else val_metrics['f1'])\n","\n","    # save best\n","    if val_metrics['auc'] > best_val:\n","        best_val = val_metrics['auc']\n","        best_state = {\n","            'model': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'epoch': epoch,\n","            'val': val_metrics\n","        }\n","        torch.save(best_state, CKPT_PATH)\n","        print(\"  --> saved best model\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wA0KL3o1Limf","executionInfo":{"status":"ok","timestamp":1765536681057,"user_tz":-330,"elapsed":98852,"user":{"displayName":"Dev Kalra","userId":"06956701992542561494"}},"outputId":"0f5dcb11-417e-46ac-ba4e-cf1767d11b9b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 01 loss 1.125103  val_auc 0.6944  val_f1 0.2926\n","  --> saved best model\n","Epoch 02 loss 1.111750  val_auc 0.6959  val_f1 0.2921\n","  --> saved best model\n","Epoch 03 loss 1.110088  val_auc 0.6954  val_f1 0.2954\n","Epoch 04 loss 1.108688  val_auc 0.6960  val_f1 0.2918\n","  --> saved best model\n","Epoch 05 loss 1.108385  val_auc 0.6983  val_f1 0.2969\n","  --> saved best model\n","Epoch 06 loss 1.106619  val_auc 0.6970  val_f1 0.2966\n","Epoch 07 loss 1.106910  val_auc 0.6957  val_f1 0.2932\n","Epoch 08 loss 1.105179  val_auc 0.6983  val_f1 0.2942\n","  --> saved best model\n","Epoch 09 loss 1.103831  val_auc 0.6973  val_f1 0.2909\n","Epoch 10 loss 1.103403  val_auc 0.6968  val_f1 0.2897\n","Epoch 11 loss 1.102219  val_auc 0.6986  val_f1 0.2923\n","  --> saved best model\n","Epoch 12 loss 1.101543  val_auc 0.6968  val_f1 0.2932\n","Epoch 13 loss 1.101975  val_auc 0.6985  val_f1 0.2944\n","Epoch 14 loss 1.101575  val_auc 0.6979  val_f1 0.2929\n","Epoch 15 loss 1.102107  val_auc 0.6985  val_f1 0.2948\n","Epoch 16 loss 1.099842  val_auc 0.6982  val_f1 0.2945\n","Epoch 17 loss 1.100283  val_auc 0.6984  val_f1 0.2944\n","Epoch 18 loss 1.099450  val_auc 0.6985  val_f1 0.2951\n","Epoch 19 loss 1.099752  val_auc 0.6989  val_f1 0.2961\n","  --> saved best model\n","Epoch 20 loss 1.098664  val_auc 0.6981  val_f1 0.2952\n","Epoch 21 loss 1.097393  val_auc 0.6979  val_f1 0.2946\n","Epoch 22 loss 1.098660  val_auc 0.6976  val_f1 0.2927\n","Epoch 23 loss 1.100287  val_auc 0.6987  val_f1 0.2961\n","Epoch 24 loss 1.097430  val_auc 0.6980  val_f1 0.2943\n","Epoch 25 loss 1.098704  val_auc 0.6986  val_f1 0.2954\n","Epoch 26 loss 1.096367  val_auc 0.6986  val_f1 0.2957\n","Epoch 27 loss 1.096662  val_auc 0.6983  val_f1 0.2952\n","Epoch 28 loss 1.097146  val_auc 0.6986  val_f1 0.2956\n","Epoch 29 loss 1.096822  val_auc 0.6984  val_f1 0.2941\n","Epoch 30 loss 1.097111  val_auc 0.6985  val_f1 0.2949\n"]}]},{"cell_type":"code","source":["EPOCHS = 30\n","best_val = -1\n","best_state = None\n","\n","for epoch in range(1, EPOCHS+1):\n","    model.train()\n","    epoch_loss = 0.0\n","    for xb, yb in train_loader:\n","        xb = xb.to(DEVICE).float()\n","        yb = yb.to(DEVICE).float()\n","        optimizer.zero_grad()\n","        logits = model(xb)\n","        loss = criterion(logits, yb)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_loss += loss.item() * xb.size(0)\n","    epoch_loss = epoch_loss / len(train_loader.dataset)\n","\n","    # eval\n","    val_metrics = eval_on(val_loader)\n","    print(f\"Epoch {epoch:02d} loss {epoch_loss:.4f}  val_auc {val_metrics['auc']:.4f}  val_f1 {val_metrics['f1']:.4f}\")\n","\n","    # scheduler and save best\n","    scheduler.step(val_metrics['auc'] if not math.isnan(val_metrics['auc']) else val_metrics['f1'])\n","    if val_metrics['auc'] > best_val:\n","        best_val = val_metrics['auc']\n","        best_state = { 'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch, 'val': val_metrics }\n","        # save checkpoint to Drive\n","        torch.save(best_state, \"/content/drive/MyDrive/loan-data/best_mlp_checkpoint.pt\")\n","        print(\"  --> saved best model\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hOYdMSS5JJfG","executionInfo":{"status":"ok","timestamp":1765536884493,"user_tz":-330,"elapsed":124209,"user":{"displayName":"Dev Kalra","userId":"06956701992542561494"}},"outputId":"14f64aa8-e52b-4402-e404-f8e5109b08fc"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 01 loss 1.0965  val_auc 0.6986  val_f1 0.2950\n","  --> saved best model\n","Epoch 02 loss 1.0965  val_auc 0.6988  val_f1 0.2951\n","  --> saved best model\n","Epoch 03 loss 1.0960  val_auc 0.6985  val_f1 0.2951\n","Epoch 04 loss 1.0957  val_auc 0.6986  val_f1 0.2951\n","Epoch 05 loss 1.0971  val_auc 0.6989  val_f1 0.2946\n","  --> saved best model\n","Epoch 06 loss 1.0955  val_auc 0.6987  val_f1 0.2947\n","Epoch 07 loss 1.0953  val_auc 0.6987  val_f1 0.2950\n","Epoch 08 loss 1.0966  val_auc 0.6988  val_f1 0.2932\n","Epoch 09 loss 1.0963  val_auc 0.6985  val_f1 0.2952\n","Epoch 10 loss 1.0953  val_auc 0.6988  val_f1 0.2945\n","Epoch 11 loss 1.0951  val_auc 0.6987  val_f1 0.2950\n","Epoch 12 loss 1.0969  val_auc 0.6986  val_f1 0.2952\n","Epoch 13 loss 1.0959  val_auc 0.6982  val_f1 0.2920\n","Epoch 14 loss 1.0957  val_auc 0.6987  val_f1 0.2950\n","Epoch 15 loss 1.0945  val_auc 0.6987  val_f1 0.2958\n","Epoch 16 loss 1.0965  val_auc 0.6989  val_f1 0.2959\n","  --> saved best model\n","Epoch 17 loss 1.0961  val_auc 0.6989  val_f1 0.2953\n","  --> saved best model\n","Epoch 18 loss 1.0959  val_auc 0.6989  val_f1 0.2955\n","  --> saved best model\n","Epoch 19 loss 1.0943  val_auc 0.6987  val_f1 0.2951\n","Epoch 20 loss 1.0944  val_auc 0.6989  val_f1 0.2956\n","Epoch 21 loss 1.0960  val_auc 0.6985  val_f1 0.2941\n","Epoch 22 loss 1.0947  val_auc 0.6990  val_f1 0.2964\n","  --> saved best model\n","Epoch 23 loss 1.0961  val_auc 0.6987  val_f1 0.2943\n","Epoch 24 loss 1.0961  val_auc 0.6986  val_f1 0.2950\n","Epoch 25 loss 1.0959  val_auc 0.6987  val_f1 0.2949\n","Epoch 26 loss 1.0958  val_auc 0.6985  val_f1 0.2930\n","Epoch 27 loss 1.0964  val_auc 0.6989  val_f1 0.2942\n","Epoch 28 loss 1.0945  val_auc 0.6982  val_f1 0.2918\n","Epoch 29 loss 1.0955  val_auc 0.6988  val_f1 0.2949\n","Epoch 30 loss 1.0955  val_auc 0.6985  val_f1 0.2944\n"]}]},{"cell_type":"code","source":["# load best\n","ckpt = torch.load(\"/content/drive/MyDrive/loan-data/best_mlp_checkpoint.pt\", map_location=DEVICE)\n","model.load_state_dict(ckpt['model'])\n","print(\"Loaded checkpoint epoch\", ckpt['epoch'])\n","\n","test_metrics = eval_on(test_loader)\n","print(\"Test metrics:\")\n","print(f\" AUC:  {test_metrics['auc']:.4f}\")\n","print(f\" F1:   {test_metrics['f1']:.4f}\")\n","print(f\" Prec: {test_metrics['precision']:.4f}\")\n","print(f\" Rec:  {test_metrics['recall']:.4f}\")\n","\n","# Save a small CSV of predictions vs labels for analysis\n","probs, labels = get_preds_labels(test_loader)\n","out_df = pd.DataFrame({'prob':probs, 'pred':(probs>=0.5).astype(int), 'label':labels})\n","out_df.to_csv('/content/drive/MyDrive/loan-data/test_predictions.csv', index=False)\n","print(\"Saved test_predictions.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZB8S68FKMSFI","executionInfo":{"status":"ok","timestamp":1765536885169,"user_tz":-330,"elapsed":658,"user":{"displayName":"Dev Kalra","userId":"06956701992542561494"}},"outputId":"53f05d9f-f0de-4a74-b86f-d8c076bbb5a9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded checkpoint epoch 22\n","Test metrics:\n"," AUC:  0.6891\n"," F1:   0.2914\n"," Prec: 0.1864\n"," Rec:  0.6675\n","Saved test_predictions.csv\n"]}]},{"cell_type":"markdown","source":["Model: MLP with two hidden layers [256,128], BatchNorm, Dropout(0.2).\n","Loss: BCEWithLogitsLoss with pos_weight to correct class imbalance.\n","Train/Val/Test splits: 64% / 16% / 20% (stratified by target).\n","Metrics reported: AUC (primary for probabilistic discrimination) and F1 (binary decision quality).\n","Files saved to Drive:\n","- best_mlp_checkpoint.pt\n","- test_predictions.csv\n","Recommended next steps:\n","- tune architecture and learning rate via small grid search\n","- calibrate predicted probabilities (Platt or isotonic)\n","- experiment with class-threshold other than 0.5 to maximize business metric (expected profit)\n"],"metadata":{"id":"R3WnDafBMjOH"}}]}